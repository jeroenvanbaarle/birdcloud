{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demographic-domain",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeroen\\miniconda3\\envs\\py310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wradlib\n",
    "import xarray as xr\n",
    "import parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "specified-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCloud:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Prepares BirdCloud object\n",
    "\n",
    "        The object contains radar, product and projection metadata and a potentially range limited point cloud.\n",
    "        \"\"\"\n",
    "        self.source = None\n",
    "        self.radar = dict()\n",
    "        self.product = dict()\n",
    "        self.scans = dict()\n",
    "        self.pointcloud = None\n",
    "        self.range_limit = None\n",
    "        self.projection = None\n",
    "        self._elevations = []\n",
    "\n",
    "    def from_raw_knmi_file(self, filepath, range_limit=None, dr_thresh=-12):\n",
    "        \"\"\"\n",
    "        Builds point cloud from KNMI radar HDF5 file\n",
    "\n",
    "        :param filepath: path to the raw KNMI radar HDF5 file\n",
    "        :param range_limit: None or iterable containing both minimum and maximum range of the point cloud from the radar\n",
    "            site.\n",
    "        \"\"\"\n",
    "        f = h5py.File(filepath, 'r')\n",
    "        self.source = filepath\n",
    "        self.range_limit = range_limit\n",
    "\n",
    "        self.parse_knmi_metadata(f)\n",
    "        self.extract_knmi_scans(f)\n",
    "        self.calculate_additional_metrics()\n",
    "        self.label_biology_using_depolarization_ratio(thresh=dr_thresh)\n",
    "        self.flatten_scans_to_pointcloud()\n",
    "        self.drop_na_rows()\n",
    "        self.set_column_order()\n",
    "\n",
    "    def from_odim_file(self, filepath, range_limit=None, dr_thresh=-12):\n",
    "        \"\"\"\n",
    "        Builds point cloud from ODIM formatted polar volume\n",
    "\n",
    "        :param filepath: path to the ODIM formatted HDF5 file\n",
    "        :param range_limit: None or iterable containing both minimum and maximum range of the point cloud from the radar\n",
    "            site.\n",
    "        :param dr_thresh: Threshold of depolarization ratio to label biology and meteorology. Values above this\n",
    "            threshold will be labeled as biology.\n",
    "        \"\"\"\n",
    "        f = h5py.File(filepath, 'r')\n",
    "        self.source = filepath\n",
    "        self.range_limit = range_limit\n",
    "\n",
    "        self.parse_odim_metadata(f)\n",
    "        self.extract_odim_scans(f)\n",
    "        self.calculate_additional_metrics()\n",
    "        self.label_biology_using_depolarization_ratio(thresh=dr_thresh)\n",
    "        self.flatten_scans_to_pointcloud()\n",
    "        self.drop_na_rows()\n",
    "        self.set_column_order()\n",
    "\n",
    "    def parse_knmi_metadata(self, file):\n",
    "        \"\"\"\n",
    "        Parses KNMI metadata from HDF5 file about the radar itself and the provided radar products\n",
    "        :param file: KNMI formatted HDF5 file object\n",
    "        \"\"\"\n",
    "        self.radar['name'] = file['radar1'].attrs.get('radar_name').decode('UTF-8')\n",
    "        latlon = file['radar1'].attrs.get('radar_location')\n",
    "        self.radar['latitude'] = latlon[1]\n",
    "        self.radar['longitude'] = latlon[0]\n",
    "        self.radar['altitude'] = self.radar_metadata[self.radar['name']]['altitude']\n",
    "        self.radar['polarization'] = self.radar_metadata[self.radar['name']]['polarization']\n",
    "\n",
    "        dt_format = '%d-%b-%Y;%H:%M:%S.%f'\n",
    "        dt_start = file['overview'].attrs.get('product_datetime_start').decode('UTF-8')\n",
    "        dt_end = file['overview'].attrs.get('product_datetime_end').decode('UTF-8')\n",
    "        self.product['datetime_start'] = datetime.strptime(dt_start, dt_format)\n",
    "        self.product['datetime_end'] = datetime.strptime(dt_end, dt_format)\n",
    "\n",
    "    def parse_odim_metadata(self, file):\n",
    "        \"\"\"\n",
    "        Parses ODIM metadata from HDF5 file about radar itself and the provided radar products\n",
    "\n",
    "        Volume scan start and end times are derived from start time of the 1st scan and end time of the 16th scan, as\n",
    "        scans are numbered chronologically.\n",
    "        :param file: ODIM formatted HDF5 file object\n",
    "        \"\"\"\n",
    "        source = dict(pair.split(':') for pair in file['what'].attrs.get('source').decode('UTF-8').split(','))\n",
    "        self.radar['name'] = source['PLC'].replace(\" \", \"\") if source.get('PLC') is not None else source.get('WMO')\n",
    "        self.radar['latitude'] = file['where'].attrs.get('lat')[0]\n",
    "        self.radar['longitude'] = file['where'].attrs.get('lon')[0]\n",
    "        self.radar['altitude'] = file['where'].attrs.get('height')[0]\n",
    "        self.radar['polarization'] = self.radar_metadata[self.radar['name']]['polarization']\n",
    "\n",
    "        time_start = datetime.strptime(file['dataset1']['what'].attrs.get('starttime').decode('UTF-8'), '%H%M%S').time()\n",
    "        date_start = datetime.strptime(file['dataset1']['what'].attrs.get('startdate').decode('UTF-8'), '%Y%m%d').date()\n",
    "        self.product['datetime_start'] = datetime.combine(date_start, time_start)\n",
    "        time_end = datetime.strptime(file['dataset16']['what'].attrs.get('endtime').decode('UTF-8'), '%H%M%S').time()\n",
    "        date_end = datetime.strptime(file['dataset16']['what'].attrs.get('enddate').decode('UTF-8'), '%Y%m%d').date()\n",
    "        self.product['datetime_end'] = datetime.combine(date_end, time_end)\n",
    "\n",
    "    def extract_knmi_scans(self, file):\n",
    "        \"\"\"\n",
    "        Iterates over all scans and corresponding datasets in the KNMI formatted HDF5 files and stores all scans in\n",
    "        self.scans dictionary as Xarray Datasets, accessible by elevation keys.\n",
    "\n",
    "        :param file: KNMI formatted HDF5 file object\n",
    "        \"\"\"\n",
    "        for group in file:\n",
    "            if not file[group].name.startswith('scan', 1):\n",
    "                continue\n",
    "\n",
    "            if file[group].name in self.excluded_scans:\n",
    "                continue\n",
    "\n",
    "            elevation = round(file[group].attrs.get('scan_elevation')[0], 1)\n",
    "            n_range_bins = file[group].attrs.get('scan_number_range')[0]\n",
    "            n_azim_bins = file[group].attrs.get('scan_number_azim')[0]\n",
    "            bin_range = file[group].attrs.get('scan_range_bin')[0]\n",
    "            site_coords = [self.radar['longitude'], self.radar['latitude'], self.radar['altitude'] / 1000]\n",
    "\n",
    "            bin_range_min, bin_range_max = self.calculate_bin_range_limits(self.range_limit, bin_range, n_range_bins)\n",
    "\n",
    "            x, y, z, ranges, azimuths = self.calculate_xyz(site_coords, elevation, n_azim_bins,\n",
    "                                                           bin_range, bin_range_min, bin_range_max)\n",
    "\n",
    "            datasets = {}\n",
    "\n",
    "            for dataset in file[group]:\n",
    "                try:\n",
    "                    ds, quantity = self.parse_knmi_dataset(file[group][dataset], bin_range_min, bin_range_max,\n",
    "                                                           ranges, azimuths)\n",
    "\n",
    "                    datasets[quantity] = ds\n",
    "\n",
    "                except TypeError:\n",
    "                    continue\n",
    "\n",
    "            dataset = xr.Dataset(data_vars=datasets,\n",
    "                                 coords={'azimuth': azimuths,\n",
    "                                         'range': ranges,\n",
    "                                         'x': (['azimuth', 'range'], x),\n",
    "                                         'y': (['azimuth', 'range'], y),\n",
    "                                         'z': (['azimuth', 'range'], z)},\n",
    "                                 attrs={'elevation': elevation,\n",
    "                                        'n_range_bins': n_range_bins,\n",
    "                                        'n_azim_bins': n_azim_bins,\n",
    "                                        'bin_range': bin_range,})\n",
    "\n",
    "            self.scans[str(elevation)] = dataset\n",
    "            self._elevations.append(elevation)\n",
    "\n",
    "    def parse_knmi_dataset(self, dataset, bin_range_min, bin_range_max, ranges, azimuths):\n",
    "        \"\"\"\n",
    "        Parses a single dataset within a scan by converting it using the calibration formula and storing it as an\n",
    "        Xarray DataArray.\n",
    "\n",
    "        All missing data is marked as np.nan.\n",
    "\n",
    "        :param dataset: KNMI HDF5 file object with path to a radar dataset\n",
    "        :param bin_range_min: the index of the first bin that falls within the instance range_limit\n",
    "        :param bin_range_max: the index of the last bin that falls within the instance range_limit\n",
    "        :param ranges: grid of range values corresponding to each of the cells in the dataset array\n",
    "        :param azimuths: grid of azimuth values corresponding to each of the cells in the dataset array\n",
    "        :return: converted KNMI dataset as Xarray DataArray and corresponding ODIM compatible product (quantity) name\n",
    "        \"\"\"\n",
    "        dataset_name = dataset.name.replace(dataset.parent.name + '/', '')\n",
    "\n",
    "        if not dataset_name.startswith('scan_'):\n",
    "            return None\n",
    "\n",
    "        quantity = dataset_name.lstrip('scan_').rstrip('_data')\n",
    "        odim_quantity = self.available_datasets[self.radar['polarization']][quantity]['ODIM']\n",
    "\n",
    "        if quantity in self.excluded_datasets[self.radar['polarization']]:\n",
    "            return None\n",
    "\n",
    "        calibration_identifier = 'calibration_{}_formulas'.format(quantity)\n",
    "        calibration_formula = dataset.parent['calibration'].attrs.get(calibration_identifier).decode('UTF-8')\n",
    "        gain, offset = calibration_formula.lstrip('GEO=').split('*PV+')\n",
    "        gain = np.float64(gain)\n",
    "        offset = np.float64(offset)\n",
    "        nodata = dataset.parent['calibration'].attrs.get('calibration_missing_data')\n",
    "        undetect = nodata\n",
    "\n",
    "        raw_data = dataset[:, bin_range_min:bin_range_max]\n",
    "        missing = np.logical_or(raw_data == nodata, raw_data == undetect)\n",
    "\n",
    "        corrected_data = raw_data * gain + offset\n",
    "        corrected_data[missing] = np.nan\n",
    "\n",
    "        ds = xr.DataArray(corrected_data, coords=[azimuths, ranges], dims=['azimuth', 'range'])\n",
    "\n",
    "        return ds, odim_quantity\n",
    "\n",
    "    def extract_odim_scans(self, file):\n",
    "        \"\"\"\n",
    "        Iterates over all scans and corresponding datasets in the ODIM formatted HDF5 files and stores all scans in\n",
    "        self.scans dictionary as Xarray Datasets, accessible by elevation keys.\n",
    "\n",
    "        :param file: ODIM formatted HDF5 file object\n",
    "        \"\"\"\n",
    "        for group in file:\n",
    "            if not file[group].name.startswith('dataset', 1):\n",
    "                continue\n",
    "\n",
    "            if file[group].name in self.excluded_scans:\n",
    "                continue\n",
    "\n",
    "            elevation = round(file[group]['where'].attrs.get('elangle')[0], 1)\n",
    "            n_range_bins = file[group]['where'].attrs.get('nbins')[0]\n",
    "            n_azim_bins = file[group]['where'].attrs.get('nrays')[0]\n",
    "            bin_range = file[group]['where'].attrs.get('rscale')[0] / 1000\n",
    "            site_coords = [self.radar['longitude'], self.radar['latitude'], self.radar['altitude'] / 1000]\n",
    "\n",
    "            bin_range_min, bin_range_max = self.calculate_bin_range_limits(self.range_limit, bin_range, n_range_bins)\n",
    "\n",
    "            x, y, z, ranges, azimuths = self.calculate_xyz(site_coords, elevation, n_azim_bins,\n",
    "                                                           bin_range, bin_range_min, bin_range_max)\n",
    "\n",
    "            datasets = {}\n",
    "\n",
    "            for dataset in file[group]:\n",
    "                try:\n",
    "                    ds, quantity = self.parse_odim_dataset(file[group][dataset], bin_range_min, bin_range_max,\n",
    "                                                           ranges, azimuths)\n",
    "\n",
    "                    datasets[quantity] = ds\n",
    "\n",
    "                except TypeError:\n",
    "                    continue\n",
    "\n",
    "            dataset = xr.Dataset(data_vars=datasets,\n",
    "                                 coords={'azimuth': azimuths,\n",
    "                                         'range': ranges,\n",
    "                                         'x': (['azimuth', 'range'], x),\n",
    "                                         'y': (['azimuth', 'range'], y),\n",
    "                                         'z': (['azimuth', 'range'], z)},\n",
    "                                 attrs={'elevation': elevation,\n",
    "                                        'n_range_bins': n_range_bins,\n",
    "                                        'n_azim_bins': n_azim_bins,\n",
    "                                        'bin_range': bin_range})\n",
    "\n",
    "            self.scans[str(elevation)] = dataset\n",
    "            self._elevations.append(elevation)\n",
    "\n",
    "    def parse_odim_dataset(self, dataset, bin_range_min, bin_range_max, ranges, azimuths):\n",
    "        \"\"\"\n",
    "        Parses a single dataset within a scan by converting it using the calibration formula and storing it as an\n",
    "        Xarray DataArray.\n",
    "\n",
    "        All missing data is marked as np.nan.\n",
    "\n",
    "        :param dataset: ODIM HDF5 file object with path to a radar dataset\n",
    "        :param bin_range_min: the index of the first bin that falls within the instance range_limit\n",
    "        :param bin_range_max: the index of the last bin that falls within the instance range_limit\n",
    "        :param ranges: grid of range values corresponding to each of the cells in the dataset array\n",
    "        :param azimuths: grid of azimuth values corresponding to each of the cells in the dataset array\n",
    "        :return: converted ODIM dataset as Xarray DataArray and corresponding product (quantity) name\n",
    "        \"\"\"\n",
    "        dataset_name = dataset.name.replace(dataset.parent.name + '/', '')\n",
    "\n",
    "        if not dataset_name.startswith('data'):\n",
    "            return None\n",
    "\n",
    "        quantity = dataset['what'].attrs.get('quantity').decode('UTF-8')\n",
    "\n",
    "        if quantity in self.excluded_datasets[self.radar['polarization']]:\n",
    "            return None\n",
    "\n",
    "        gain = dataset['what'].attrs.get('gain')[0]\n",
    "        offset = dataset['what'].attrs.get('offset')[0]\n",
    "        nodata = dataset['what'].attrs.get('nodata')[0]\n",
    "        undetect = dataset['what'].attrs.get('undetect')[0]\n",
    "\n",
    "        raw_data = dataset['data'][:, bin_range_min:bin_range_max]\n",
    "        missing = np.logical_or(raw_data == nodata, raw_data == undetect)\n",
    "\n",
    "        corrected_data = raw_data * gain + offset\n",
    "        corrected_data[missing] = np.nan\n",
    "\n",
    "        ds = xr.DataArray(corrected_data, coords=[azimuths, ranges], dims=['azimuth', 'range'])\n",
    "\n",
    "        return ds, quantity\n",
    "\n",
    "    def calculate_bin_range_limits(self, range_limit, bin_range, n_range_bins):\n",
    "        \"\"\"\n",
    "        Calculates range of bins to select for all to fall within provided range_limit.\n",
    "\n",
    "        If the lower limit is None, it will be converted to 0. If the upper limit is None, it will be converted to the\n",
    "        maximum value of the range, i.e. n_range_bins.\n",
    "\n",
    "        E.g. this function will return the 6th bin as bins_min if the minimum range limit is set to 5 (km) and the\n",
    "            bin_range is 0.900: 5/0.900 = 5.5555 -> 6\n",
    "\n",
    "        :param range_limit: iterable containing successively a minimum and maximum range\n",
    "        :param bin_range: range covered by a single bin in the same units as range_limit\n",
    "        :param n_range_bins: the number of range bins within a scan\n",
    "        :return: indexes for the first (bins_min) and last (bins_max) bins that fall within the given range_limit\n",
    "        \"\"\"\n",
    "        if range_limit is None:\n",
    "            range_limit = [None, None]\n",
    "\n",
    "        minimum = range_limit[0] if range_limit[0] is not None else 0\n",
    "        maximum = range_limit[1] if range_limit[1] is not None else n_range_bins\n",
    "\n",
    "        bins_min = math.ceil(minimum / bin_range)\n",
    "        if bins_min > n_range_bins:\n",
    "            raise ValueError('Minimum range set too high: no datapoints remaining.')\n",
    "\n",
    "        bins_max = math.floor(maximum / bin_range)\n",
    "        if bins_max > n_range_bins:\n",
    "            bins_max = n_range_bins\n",
    "\n",
    "        return bins_min, bins_max\n",
    "\n",
    "    def calculate_xyz(self, sitecoords, elevation_angle, n_azim_bins, bin_range, bin_range_min, bin_range_max):\n",
    "        \"\"\"\n",
    "        Calculates X, Y and Z coordinates for centers of all radar bins using wradlib and sets self.projection to the\n",
    "        corresponding georeferencing information.\n",
    "\n",
    "        :param sitecoords: iterable containing coordinates and altitude of radar site, in the order of: longitude,\n",
    "            latitude, altitude\n",
    "        :param elevation_angle: elevation angle of the radar scan\n",
    "        :param n_azim_bins: number of azimuthal bins of the radar scan (usually 360)\n",
    "        :param bin_range: range covered by every bin (usually in kilometers). Should be in the same units as the radar\n",
    "            altitude\n",
    "        :param bin_range_min: index of the first range bin to calculate X, Y and Z coordinates for\n",
    "        :param bin_range_max: index of the last range bin to calculate X, Y and Z coordinates for\n",
    "        :return: numpy arrays for the X, Y and Z coordinates and ranges and azimuths\n",
    "        \"\"\"\n",
    "        if sitecoords is None:\n",
    "            sitecoords = (0, 0)\n",
    "\n",
    "        n_range_bins = bin_range_max - bin_range_min\n",
    "        range_min = bin_range_min * bin_range\n",
    "        range_max = bin_range_max * bin_range\n",
    "        ranges = np.linspace(range_min, range_max, n_range_bins)\n",
    "        azimuths = np.arange(0, n_azim_bins)\n",
    "\n",
    "        polargrid = np.meshgrid(ranges, azimuths)\n",
    "\n",
    "        xyz, self.projection = wradlib.georef.polar.spherical_to_xyz(polargrid[0], polargrid[1], elevation_angle,\n",
    "                                                                     sitecoords, re=6378000, squeeze=True)\n",
    "\n",
    "        return xyz[:, :, 0], xyz[:, :, 1], xyz[:, :, 2], ranges, azimuths\n",
    "\n",
    "    def calculate_additional_metrics(self):\n",
    "        \"\"\"\n",
    "        Triggers calculation of other metrics, such as ZDR calculation, textures etc.\n",
    "        \"\"\"\n",
    "        self.calculate_differential_reflectivity()\n",
    "        self.calculate_depolarization_ratio()\n",
    "\n",
    "    def calculate_differential_reflectivity(self):\n",
    "        \"\"\"\n",
    "        Calculates differential reflectivity or ZDR, defined as DBZH - DBZV (following Stepanian et al., 2016).\n",
    "        \"\"\"\n",
    "        for elevation in self.scans:\n",
    "            self.scans[elevation]['ZDR'] = self.scans[elevation]['DBZH'] - self.scans[elevation]['DBZV']\n",
    "\n",
    "    def calculate_depolarization_ratio(self):\n",
    "        \"\"\"\n",
    "        Calculated depolarization ratio following Kilambi et al. (2018).\n",
    "\n",
    "        DR = 10 * log10((ZDR + 1 - 2 * ZDR^0.5 * RHOHV) / (ZDR + 1 + 2 * ZDR^0.5 * RHOHV))\n",
    "        \"\"\"\n",
    "        for elevation in self.scans:\n",
    "            self.scans[elevation]['DR'] = 10 * np.log10((self.scans[elevation]['ZDR'] + 1 - 2 * np.sqrt(self.scans[elevation]['ZDR']) * self.scans[elevation]['RHOHV']) /\n",
    "                                                        (self.scans[elevation]['ZDR'] + 1 + 2 * np.sqrt(self.scans[elevation]['ZDR']) * self.scans[elevation]['RHOHV']))\n",
    "\n",
    "    def label_biology_using_depolarization_ratio(self, thresh=-12):\n",
    "        \"\"\"\n",
    "        Following Kilambi et al. (2018) and labelling as biology anything above a depolarization ratio of -12 seems to\n",
    "        work fairly well, so we'll use that, but threshold can be overridden.\n",
    "        \"\"\"\n",
    "        for elevation in self.scans:\n",
    "            self.scans[elevation]['biology'] = (self.scans[elevation]['DR'] > thresh) * 1\n",
    "\n",
    "    def flatten_scans_to_pointcloud(self):\n",
    "        \"\"\"\n",
    "        The function that 'builds' the pointcloud by flattening the self.scans dictionary into a single Pandas dataframe\n",
    "        self.pointcloud. This is a necessary step to e.g. save the pointcloud in a CSV file for viewing in CloudCompare.\n",
    "        \"\"\"\n",
    "        for elevation in self.scans:\n",
    "            dataframe = self.scans[elevation].to_dataframe()\n",
    "            dataframe['elevation'] = elevation\n",
    "            dataframe.reset_index(inplace=True)\n",
    "\n",
    "            if isinstance(self.pointcloud, pd.DataFrame):\n",
    "                self.pointcloud = self.pointcloud.append(dataframe)\n",
    "            else:\n",
    "                self.pointcloud = dataframe\n",
    "\n",
    "    def drop_na_rows(self, subset=None):\n",
    "        \"\"\"\n",
    "        Drops rows from the file where columns in subset containg NA/NaN values. By default this is done for rows that\n",
    "        contain no values for DBZH and VRADH.\n",
    "\n",
    "        :param subset: Iterable of column names that cannot have NA/NaN values in rows.\n",
    "        \"\"\"\n",
    "        if subset is None:\n",
    "            subset = ['DBZH', 'VRADH']\n",
    "\n",
    "        self.pointcloud.dropna(subset=subset, inplace=True)\n",
    "\n",
    "    def set_column_order(self):\n",
    "        \"\"\"\n",
    "        Orders columns in order defined in self.column_order for both single-pol and dual-pol polarizations.\n",
    "        \"\"\"\n",
    "        order = self.column_order[self.radar['polarization']]\n",
    "        columns_unordered = list(self.pointcloud.columns)\n",
    "        columns_ordered = [variable for variable in order if variable in columns_unordered]\n",
    "        self.pointcloud = self.pointcloud[columns_ordered]\n",
    "        self.pointcloud.set_index(['elevation', 'azimuth', 'range'], inplace=True)\n",
    "\n",
    "    def to_csv(self, file_path, compression=None, float_format=None):\n",
    "        \"\"\"\n",
    "        Exports the point cloud to a CSV file.\n",
    "        :param file_path: path to CSV file. If the file does not exist yet, it will be created.\n",
    "        \"\"\"\n",
    "        self.pointcloud.to_csv(file_path, na_rep=\"NaN\", quotechar='\"', index=False, compression=compression,\n",
    "                               float_format=float_format)\n",
    "\n",
    "    @property\n",
    "    def elevations(self):\n",
    "        return sorted(self._elevations)\n",
    "\n",
    "    @elevations.setter\n",
    "    def elevations(self, value):\n",
    "        self._elevations.append(value)\n",
    "\n",
    "    radar_metadata = {\n",
    "        'DeBilt': {'altitude': 44, 'polarization': 'SinglePol'},\n",
    "        'DenHelder': {'altitude': 51, 'polarization': 'DualPol'},\n",
    "        'Herwijnen': {'altitude': 27.7, 'polarization': 'DualPol'}\n",
    "    }\n",
    "\n",
    "    excluded_scans = {'/scan1', '/scan7', '/scan16', '/dataset1', '/dataset7', '/dataset16'}\n",
    "\n",
    "    available_datasets = {\n",
    "        'SinglePol': {\n",
    "            'uZ': {'description': 'Uncorrected reflectivity', 'ODIM': 'TH'},\n",
    "            'V': {'description': 'Radial velocity', 'ODIM': 'VRADH'},\n",
    "            'Z': {'description': 'Reflectivity (corrected)', 'ODIM': 'DBZH'},\n",
    "            'W': {'description': 'Spectral width of radial velocity', 'ODIM': 'WRADH'},\n",
    "            'TX_power': {'description': 'Total reflectivity factor', 'ODIM': None}\n",
    "        },\n",
    "        'DualPol': {\n",
    "            'CCOR': {'description': 'Clutter correction (horizontally polarized)', 'ODIM': 'CCORH'},\n",
    "            'CCORv': {'description': 'Clutter correction (vertically polarized)', 'ODIM': 'CCORV'},\n",
    "            'CPA': {'description': 'Clutter phase alignment (horizontally polarized)', 'ODIM': 'CPAH'},\n",
    "            'CPAv': {'description': 'Clutter phase alignment (vertically polarized)', 'ODIM': 'CPAV'},\n",
    "            'KDP': {'description': 'Specific differential phase', 'ODIM': 'KDP'},\n",
    "            'PhiDP': {'description': 'Differential phase', 'ODIM': 'PHIDP'},\n",
    "            'RhoHV': {'description': 'Correlation between Z(h) and Zv', 'ODIM': 'RHOHV'},\n",
    "            'SQI': {'description': 'Signal quality index (horizontally polarized)', 'ODIM': 'SQIH'},\n",
    "            'SQIv': {'description': 'Signal quality index (vertically polarized)', 'ODIM': 'SQIV'},\n",
    "            'TX_power': {'description': 'Total reflectivity factor', 'ODIM': None},\n",
    "            'uPhiDP': {'description': 'Unsmoothed differential phase', 'ODIM': 'PHIDPU'},\n",
    "            'uZ': {'description': 'Uncorrected reflectivity (horizontally polarized)', 'ODIM': 'TH'},\n",
    "            'uZv': {'description': 'Uncorrected reflectivity (vertically polarized)', 'ODIM': 'TV'},\n",
    "            'V': {'description': 'Radial velocity (horizontally polarized)', 'ODIM': 'VRADH'},\n",
    "            'Vv': {'description': 'Radial velocity (vertically polarized)', 'ODIM': 'VRADV'},\n",
    "            'W': {'description': 'Spectral width of radial velocity (horizontally polarized)', 'ODIM': 'WRADH'},\n",
    "            'Wv': {'description': 'Spectral width of radial velocity (vertically polarized)', 'ODIM': 'WRADV'},\n",
    "            'Z': {'description': 'Reflectivity (corrected, horizontally polarized)', 'ODIM': 'DBZH'},\n",
    "            'Zv': {'description': 'Reflectivity (corrected, vertically polarized)', 'ODIM': 'DBZV'}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    excluded_datasets = {\n",
    "        'SinglePol': {'CCOR', 'CCORv', 'CPA', 'CPAv', 'SQI', 'SQIv', 'TX_power',  # KNMI HDF5\n",
    "                      'CCORH', 'CCORV', 'CPAH', 'CPAV', 'SQIH', 'SQIV'},  # ODIM HDF5\n",
    "        'DualPol': {'CCOR', 'CCORv', 'CPA', 'CPAv', 'SQI', 'SQIv', 'TX_power',  # KNMI HDF5\n",
    "                    'CCORH', 'CCORV', 'CPAH', 'CPAV', 'SQIH', 'SQIV'}  # ODIM HDF5\n",
    "    }\n",
    "\n",
    "    column_order = {\n",
    "        'SinglePol': ['elevation', 'azimuth', 'range', 'x', 'y', 'z', 'DBZH', 'TH', 'VRADH', 'WRADH', 'TX_power'],\n",
    "        'DualPol': ['elevation', 'azimuth', 'range', 'x', 'y', 'z', 'DBZH', 'DBZV', 'TH', 'TV', 'VRADH', 'VRADV',\n",
    "                    'WRADH', 'WRADV', 'PHIDP', 'PHIDPU', 'RHOHV', 'KDP', 'ZDR', 'DR', 'CCORH', 'CCORV', 'CPAH', 'CPAV',\n",
    "                    'SQIH', 'SQIV', 'TX_power', 'biology']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "offensive-maintenance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeroen\\miniconda3\\envs\\py310\\lib\\site-packages\\xarray\\core\\computation.py:760: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result_data = func(*input_data)\n",
      "C:\\Users\\Jeroen\\miniconda3\\envs\\py310\\lib\\site-packages\\xarray\\core\\computation.py:760: RuntimeWarning: invalid value encountered in log10\n",
      "  result_data = func(*input_data)\n",
      "C:\\Users\\Jeroen\\AppData\\Local\\Temp\\ipykernel_19960\\3397057408.py:389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.pointcloud = self.pointcloud.append(dataframe)\n",
      "C:\\Users\\Jeroen\\AppData\\Local\\Temp\\ipykernel_19960\\3397057408.py:389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.pointcloud = self.pointcloud.append(dataframe)\n",
      "C:\\Users\\Jeroen\\AppData\\Local\\Temp\\ipykernel_19960\\3397057408.py:389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.pointcloud = self.pointcloud.append(dataframe)\n",
      "C:\\Users\\Jeroen\\AppData\\Local\\Temp\\ipykernel_19960\\3397057408.py:389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.pointcloud = self.pointcloud.append(dataframe)\n",
      "C:\\Users\\Jeroen\\AppData\\Local\\Temp\\ipykernel_19960\\3397057408.py:389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.pointcloud = self.pointcloud.append(dataframe)\n",
      "C:\\Users\\Jeroen\\AppData\\Local\\Temp\\ipykernel_19960\\3397057408.py:389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.pointcloud = self.pointcloud.append(dataframe)\n",
      "C:\\Users\\Jeroen\\AppData\\Local\\Temp\\ipykernel_19960\\3397057408.py:389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.pointcloud = self.pointcloud.append(dataframe)\n",
      "C:\\Users\\Jeroen\\AppData\\Local\\Temp\\ipykernel_19960\\3397057408.py:389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.pointcloud = self.pointcloud.append(dataframe)\n",
      "C:\\Users\\Jeroen\\AppData\\Local\\Temp\\ipykernel_19960\\3397057408.py:389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.pointcloud = self.pointcloud.append(dataframe)\n",
      "C:\\Users\\Jeroen\\AppData\\Local\\Temp\\ipykernel_19960\\3397057408.py:389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.pointcloud = self.pointcloud.append(dataframe)\n",
      "C:\\Users\\Jeroen\\AppData\\Local\\Temp\\ipykernel_19960\\3397057408.py:389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.pointcloud = self.pointcloud.append(dataframe)\n",
      "C:\\Users\\Jeroen\\AppData\\Local\\Temp\\ipykernel_19960\\3397057408.py:389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.pointcloud = self.pointcloud.append(dataframe)\n"
     ]
    }
   ],
   "source": [
    "# C:\\Users\\Jeroen\\Documents\\Studie\\Master\\Thesis\\data\n",
    "\n",
    "b = BirdCloud()\n",
    "b.from_odim_file('../../../../Documents/Studie/Master/Thesis/data/09/NLHRW_pvol_20230109T2350_6356.h5')\n",
    "b.to_csv('../../../../Documents/Studie/Master/Thesis/csvdata/NLHRW_pvol_20230109T2350_6356_2.csv')\n",
    "# b.from_odim_file('../NLHRW_pvol_20190419T2100_6356.h5')\n",
    "# b.to_csv('../NLHRW_pvol_20190419T2100_6356.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "noble-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../../Documents/Studie/Master/Thesis/csvdata/NLHRW_pvol_20230109T2350_6356.csv')\n",
    "df2 = df.copy()\n",
    "df2 = df2[['x', 'y', 'z', 'DBZH', 'DBZV', 'VRADH', 'VRADV', 'biology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "determined-display",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_max: 187.29040909706083, x_min: -187.29040909706083\n",
      "y_max: 187.29040909706083, y_min: -187.29040909706083\n",
      "z_max: 31.67362748272717, z_min: 0.0276999995112419\n",
      "DBZH_max: 79.48141317, DBZH_min: -31.49996207\n",
      "VRADH_max: 79.89767162000001, VRADH_min: -79.89996157\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_max: {df['x'].max()}, x_min: {df['x'].min()}\")\n",
    "print(f\"y_max: {df['y'].max()}, y_min: {df['y'].min()}\")\n",
    "print(f\"z_max: {df['z'].max()}, z_min: {df['z'].min()}\")\n",
    "print(f\"DBZH_max: {df['DBZH'].max()}, DBZH_min: {df['DBZH'].min()}\")\n",
    "print(f\"VRADH_max: {df['VRADH'].max()}, VRADH_min: {df['VRADH'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "prospective-adapter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3621795"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DBZH'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "biological-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nona = pd.read_csv('../../../../Documents/Studie/Master/Thesis/csvdata/NLHRW_pvol_20230109T2350_6356_2.csv')\n",
    "nona_small = df_nona.copy()\n",
    "nona_small = nona_small[['x', 'y', 'z', 'DBZH', 'VRADH', 'biology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "planned-plate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    144957\n",
       "1     80083\n",
       "Name: biology, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nona['biology'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "above-currency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>DBZH</th>\n",
       "      <th>VRADH</th>\n",
       "      <th>biology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>15.651813</td>\n",
       "      <td>-23.599051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.329537e-18</td>\n",
       "      <td>0.087038</td>\n",
       "      <td>0.051022</td>\n",
       "      <td>26.085628</td>\n",
       "      <td>-32.394468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.065907e-17</td>\n",
       "      <td>0.174076</td>\n",
       "      <td>0.074343</td>\n",
       "      <td>35.969071</td>\n",
       "      <td>-78.656362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.598861e-17</td>\n",
       "      <td>0.261114</td>\n",
       "      <td>0.097665</td>\n",
       "      <td>30.552557</td>\n",
       "      <td>-63.564919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.131815e-17</td>\n",
       "      <td>0.348152</td>\n",
       "      <td>0.120987</td>\n",
       "      <td>16.392102</td>\n",
       "      <td>72.350731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225035</th>\n",
       "      <td>-5.319960e-02</td>\n",
       "      <td>3.047803</td>\n",
       "      <td>1.137179</td>\n",
       "      <td>-27.788826</td>\n",
       "      <td>2.475081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225036</th>\n",
       "      <td>-6.206620e-02</td>\n",
       "      <td>3.555770</td>\n",
       "      <td>1.322093</td>\n",
       "      <td>-19.081707</td>\n",
       "      <td>-1.306924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225037</th>\n",
       "      <td>-6.354397e-02</td>\n",
       "      <td>3.640432</td>\n",
       "      <td>1.352912</td>\n",
       "      <td>-18.837527</td>\n",
       "      <td>0.192710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225038</th>\n",
       "      <td>-6.502174e-02</td>\n",
       "      <td>3.725093</td>\n",
       "      <td>1.383730</td>\n",
       "      <td>-22.953691</td>\n",
       "      <td>-0.663179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225039</th>\n",
       "      <td>-7.093280e-02</td>\n",
       "      <td>4.063738</td>\n",
       "      <td>1.507006</td>\n",
       "      <td>-22.362622</td>\n",
       "      <td>-1.760472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225040 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   x         y         z       DBZH      VRADH  biology\n",
       "0       0.000000e+00  0.000000  0.027700  15.651813 -23.599051        1\n",
       "1       5.329537e-18  0.087038  0.051022  26.085628 -32.394468        0\n",
       "2       1.065907e-17  0.174076  0.074343  35.969071 -78.656362        0\n",
       "3       1.598861e-17  0.261114  0.097665  30.552557 -63.564919        0\n",
       "4       2.131815e-17  0.348152  0.120987  16.392102  72.350731        0\n",
       "...              ...       ...       ...        ...        ...      ...\n",
       "225035 -5.319960e-02  3.047803  1.137179 -27.788826   2.475081        0\n",
       "225036 -6.206620e-02  3.555770  1.322093 -19.081707  -1.306924        0\n",
       "225037 -6.354397e-02  3.640432  1.352912 -18.837527   0.192710        1\n",
       "225038 -6.502174e-02  3.725093  1.383730 -22.953691  -0.663179        0\n",
       "225039 -7.093280e-02  4.063738  1.507006 -22.362622  -1.760472        1\n",
       "\n",
       "[225040 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nona_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cloudy-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../../Documents/Studie/Master/Thesis/data/PC_DEUMD_pvol_20171124T1230_10356.csv')\n",
    "df3 = df.copy()\n",
    "df3 = df[['x', 'y', 'z', 'DBZH', 'VRADH', 'biology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fallen-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "nona_small.to_parquet('../../../../Documents/Studie/Master/Thesis/csvdata/NLHRW_pvol_20230109T2350_6356_smallest.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-saver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
